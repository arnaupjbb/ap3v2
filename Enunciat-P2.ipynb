{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f00ebc7-fa25-4ceb-af8c-679254be62ba",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">\n",
    "<strong><u>Senyals i Sistemes - Pràctica 2</u></strong>\n",
    "<br/><br/>\n",
    "Aplicacions de la convolució i la correlació: El Vocoder.<h1/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ae3ae2-e945-49ca-886c-73554002e1c7",
   "metadata": {},
   "source": [
    "# <span style=\"color:#BB44DD\">Objectius</span>\n",
    "\n",
    "En aquesta pràctica continuarem treballant diversos conceptes ja coneguts dels senyals i els sistemes lineals, com ara l'energia i la potència, la periodicitat i les aplicacions de la correlació. Alhora, també treballarem conceptes nous com ara les __equacions en diferències finites__ (EDF) i el __filtrat__.\n",
    "\n",
    "Tot això, però, no ho farem només basant-nos en exemples acadèmics, sinó sobre aplicacions concretes com són l'__anàlisi de la veu humana__ i la __síntesi de veu artificial__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1137372c-4234-4340-adc0-d3b483509887",
   "metadata": {},
   "source": [
    "# <span style=\"color:#BB44DD\">Introducció</span>\n",
    "\n",
    "## Producció de la veu humana\n",
    "\n",
    "La producció del senyal de veu es realitza mitjançant un flux d'aire expel·lit pels pulmons i que passa a través de les __cordes vocals__, el __tracte vocal__ i, en ocasions, el __tracte nasal__ en paral·lel.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"VocalTract.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9425abe-9ea6-4911-bfda-7551f9a3eefb",
   "metadata": {},
   "source": [
    "## El paper de les cordes vocals: <u>Fonemes sonors i fonemes sords</u>\n",
    "\n",
    "Si durant el pas de l'aire les cordes vocals <span style=\"color: red;\">vibren</span>, produeixen una oclusió intermitent del pas de l'aire i el so resultant és aproximadament periòdic i es denomina __sonor__. Si, contràriament, les cordes vocals no vibren aleshores el so resultant no és periòdic i es denomina __sord__.\n",
    "\n",
    "Per posar alguns exemples: \n",
    "\n",
    "* Els fonemes sonors són totes les vocals i algunes consonants (b, d, g...). Aquests utilitzen generalment els tractes vocal i nasal en paral·lel per produir el so.\n",
    "* Els fonemes sords són sempre consonants (f, s, p, t, k...)\n",
    "* Hi ha fonemes sonors (m, n...) que utilitzen exclusivament el tracte nasal ja que el vocal queda obstruït per la llengua o els llavis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c861b1b-91b4-4468-8d8e-ec686b381444",
   "metadata": {},
   "source": [
    "## El paper dels tractes vocal i nasal: <u>Ressonàncies</u>\n",
    "\n",
    "Mitjançant el moviment de la llengua, els llavis, la mandíbula i els músculs que controlen la zona del coll podem variar la _<span style=\"color: red;\">forma</span>_ de les cavitats que es formen en el tracte vocal (la cavitat nasal és fixa). Això fa que aquestes cavitats __ressonin__ a freqüències diferents, cosa que afecta a la forma del senyal produït i, conseqüentment, determina el fonema que estem emetent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492be809-0fe8-4658-8ad0-dfb5b41ec580",
   "metadata": {},
   "source": [
    "## Metodologia d'anàlisi i síntesi\n",
    "\n",
    "Òbviament, la veu humana consta d'una sèrie de fonemes encadenats consecutivament, per la qual cosa de cara a l'anàlisi i la síntesi es divideix  el senyal de veu en una sèrie de __trams__ d'uns 30 milisegons de durada, en els quals se suposa que les característiques del senyal es mantenen aproximadament constants. Sovint també s'agafen els trams consecutius de manera que hi hagi un cert __solapament__ entre ells, cosa que ajuda a que les transicions entre paràmetres siguin més suaus.\n",
    "\n",
    "De tot l'anterior es dedueix que el problema de sintetitzar veu humana és complex, i l'única manera d'abordar-lo amb èxit és dividir-lo en una sèrie de subtasques més senzilles de resoldre. Això és el que farem a continuació, concretament:\n",
    "\n",
    "1. Aprendrem a visualitzar el senyal de veu i a familiaritzar-nos amb les formes que adopten els diferents fonemes.\n",
    "2. Analitzarem un fragment de veu per tal de determinar si és sord o sonor i, en aquest darrer cas, quina és la seva periodicitat i la seva energia.\n",
    "3. Pel fragment escollit, provarem de sintetitzar el mateix senyal de forma artificial fent ús de la informació recollida al pas anterior.\n",
    "4. Una vegada hàgim fet tot el procés per un sol fonema, repetirem tots els passos anteriors iterant a través de tots els fonemes d'una frase per tal de sintetitzar-la completa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ae5a54-5986-4333-9be3-e4af12725190",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5136779f-77ae-4537-a189-7977727a833e",
   "metadata": {},
   "source": [
    "# <span style=\"color:#BB44DD\">Part A: Lectura, visualització i interpretació del senyal de veu</span>\n",
    "\n",
    "1. Descarregueu els fitxers auxiliars de la pràctica i ubiqueu-los a la mateixa carpeta on teniu aquest «Notebook» de Jupyter.\n",
    "2. Executeu els fragments de codi següent, que permeten llegir un fitxer d'àudio del disc, presentar-lo visualment i reproduir-lo dins del Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed281b40-b441-41dd-88d6-ee75f90eff39",
   "metadata": {},
   "source": [
    "En aquest exemple s'utilitza un senyal de veu contingut en el fitxer «Frase.wav», corresponent a un locutor femení que llegeix una frase en llengua castellana d'uns 6 segons de durada. Consisteix en un senyal __monofònic__ i mostrejat a una freqüència de mostratge de $f_m = 8\\, \\mathrm{kHz}$ i gravat en un fitxer «WAV», on les mostres són nombres enters de 16 bits amb signe (interval [-32768..32767])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "142eeea1-8812-43cf-935d-38197a9e9edb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio\n",
    "%matplotlib inline\n",
    "#%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Llegim l'àudio del disc. «fm» serà la freqüència de mostratge del senyal\n",
    "# i «frase» serà el vector que conté les mostres de veu\n",
    "FITXER_WAV = \"Frase.wav\"\n",
    "fm, veu_original = wavfile.read(FITXER_WAV)\n",
    "\n",
    "# Els valors continguts en el fitxer d'àudio són enters de 16 bits amb signe,\n",
    "# això els normalitza a l'interval [-1..+1) i els converteix a coma flotant.\n",
    "veu_original = veu_original / 2**15\n",
    "\n",
    "# Pintem la forma d'ona. Abans creem un vector de temps adient, \n",
    "# tenint en compte que la separació entre mostres és T=1/fm\n",
    "t = np.arange(len(veu_original)) / fm\n",
    "\n",
    "# Assignem els resultats de les funcions a la «variable» \"_\" per evitar que s'imprimeixin per pantalla\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "fig,ax = plt.subplots()\n",
    "_ = ax.plot(t,veu_original)\n",
    "_ = ax.grid()\n",
    "_ = ax.set_title('Senyal de veu a estudiar')\n",
    "_ = ax.set_ylabel('Amplitud')\n",
    "_ = ax.set_xlabel('Temps [s]')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "214d59d1-09cb-4569-af95-db9a39db629c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48240"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reproduïm la frase\n",
    "veu_original = veu_original.astype(np.float32)           # Important en sistemes windows si volguéssim gravar l'àudio en un fitxer .WAV\n",
    "Audio(veu_original, rate=fm, autoplay=False)\n",
    "len(veu_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c67a8c3-0f5f-4170-bc64-871ca5f4ba4f",
   "metadata": {},
   "source": [
    "Dins del Jupyter, obriu el _notebook_ anomenat «Analitzador» en una altra pestanya __i executeu-lo__. Us ha d'aparèixer una finestra amb un conjunt de gràfiques i controls:\n",
    "\n",
    "* La gràfica superior mostra el senyal de veu en el seu conjunt, amb una franja de color taronja que ressalta el tram a analitzar\n",
    "* La gràfica central és un _zoom_ del tram a analitzar.\n",
    "* La gràfica inferior mostra l'__autocorrelació del tram__, normalitzada per tal que el màxim sigui sempre = 1.\n",
    "* A baix a l'esquerra hi ha uns botons que permeten seleccionar la «finestra» que s'aplicarà al senyal. L'objectiu de l'enfinestrat s'anirà veient poc a poc i completant en pràctiques posteriors. En aquesta pràctica treballarem amb la finestra de HAMMING i no la tocarem, tot i que podeu escollir-ne una altra per veure momentàniament les diferències.\n",
    "* A baix a la dreta hi ha una barra de desplaçament mitjançant la qual podem seleccionar un dels trams del senyal de veu per visualitzar-lo i analitzar-lo. Cada tram té una durada de 30 milisegons i pot començar en múltiples de 15 milisegons, de manera que se solapa 15ms amb el tram anterior.\n",
    "* Finalment, al dessota de la barra de desplaçament veiem informació sobre el senyal, <span style=\"color:red\">__que de moment no és funcional i haureu de completar vosaltres a l'apartat següent__</span>.\n",
    "\n",
    "<span style=\"color:red\">Podeu canviar el tram actual movent la barra de desplaçament amb el ratolí o bé utilitzant les tecles ⬅ i ➡.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f2dccf-fed0-429d-963f-f143b7b707cc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fe2523-da21-4397-b27e-73598dc6c873",
   "metadata": {},
   "source": [
    "# <span style=\"color:#BB44DD\">Part B: Anàlisi matemàtica dels diferents trams</span>\n",
    "\n",
    "En aquesta segona part l'objectiu és fer els càlculs necessaris _en cadascun dels segments o trams en què dividim la veu_ per tal de determinar alguns paràmetres essencials:\n",
    "\n",
    "1. __L'energia__ del senyal contingut en el tram de veu\n",
    "2. Si el senyal correspon a un fonema __sord__ o __sonor__.\n",
    "3. En cas que el fonema sigui _sonor_, determinar la __freqüència de vibració__ de les cordes vocals.\n",
    "\n",
    "Tot l'anterior ho farem directament modificant el codi de l'Analitzador que heu utilitzat a l'apartat A.\n",
    "\n",
    "### __IMPORTANT__: El qüestionari associat en aquest cas __no serirà per puntuar__. El seu objectiu és que serveixi com a comprovació del bon funcionament de l'algorisme que heu d'implementar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7430bf54-1d6c-4f8b-ae80-8cf494498e67",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">__Qüestió 1__</span> - Identificació dels membres del grup de treball\n",
    "\n",
    "Primer de tot, obriu el qüestionari de la pràctica i a la pregunta 1 indiqueu els membres que formen el grup de treball."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a155e9c-f137-45df-bee3-80ad44ea6c7c",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">__Qüestió 2__</span> - Càlcul de l'energia del senyal del tram\n",
    "\n",
    "__Modifiqueu el codi de la funció `analitza_segment` de l'analitzador__ per tal d'assignar a la variable _E_ el valor de l'energia del tram. Un cop fet, __reinicieu l'analitzador__ i comproveu que l'energia calculada es mostra a la part inferior dreta de la finestra. <span style=\"color: red;\">Aleshores procediu a respondre la pregunta 2 del qüestionari, seleccionant prèviament el tram que us indica l'enunciat.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f0d81a-3835-418d-96e5-c4107b450977",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">__Qüestió 3__</span> - Autocorrelació de senyals periòdics\n",
    "\n",
    "A continuació ens interessarà determinar si el tram de senyal analitzat és __sord__ o __sonor__. Del que s'ha explicat anteriorment es pot inferir que si s'està emetent un fonema __sonor__ les cordes vocals estan __vibrant__ i, per tant, el senyal produït presentarà algun tipus de __periodicitat__. En aquest cas, l'autocorrelació és una eina excel·lent per detectar i mesurar aquestes periodicitats, i a continuació en veiem els motius.\n",
    "\n",
    "Suposem que $p[n]$ és un pols, i que anomenem $r_{pp}[n]$ a la seva autocorrelació. Suposem que amb aquest pols individual construïm un senyal format per una successió de 3 polsos espaiats $N$ mostres, és a dir,\n",
    "$$ s[n] = p[n] + p[n-N] + p[n-2N] $$\n",
    "\n",
    "Executeu el següent codi, que mostra les gràfiques del pols individual, de 3 polsos consecutius i les autocorrelacions d'aquests senyals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b820418-56bb-4259-8eff-e54312dbefbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "from scipy.signal import correlate\n",
    "\n",
    "# --- Paràmetres ---\n",
    "L = 3                  # amplada del pols rectangular\n",
    "pre_pad = 2            # zeros abans del pols dins de x\n",
    "post_pad = 3           # zeros després del pols dins de x\n",
    "N = 7                  # separació entre polsos dins de s (N > L)\n",
    "assert N > L, \"Cal N > L per assegurar separació entre polsos\"\n",
    "\n",
    "# --- 1) Seqüència x: pols rectangular amb zero-padding ---\n",
    "p = np.ones(L, dtype=float)               # pols rectangular bàsic (L mostres)\n",
    "x = np.r_[np.zeros(pre_pad), p, np.zeros(post_pad)]\n",
    "n_x = np.arange(len(x))                   # índexs de x\n",
    "\n",
    "# --- 2) Autocorrelació de x -> Rx ---\n",
    "Rx_full = correlate(x, x, mode='full')    # correlació (k va de -(M-1) a +(M-1))\n",
    "lags_x = np.arange(-(len(x)-1), len(x))   # índexs k per a Rx (desfasaments)\n",
    "\n",
    "# --- 3) Seqüència s: repetició de 3 polsos separats per N mostres ---\n",
    "#     Construïm una seqüència prou llarga i hi \"pintem\" els tres polsos p\n",
    "num_pulsos = 3\n",
    "len_s = (num_pulsos - 1) * N + L\n",
    "s = np.zeros(len_s, dtype=float)\n",
    "for i in range(num_pulsos):\n",
    "    start = i * N\n",
    "    s[start:start+L] += p                 # suma (per si mai es volguessin solapar)\n",
    "n_s = np.arange(len(s))\n",
    "\n",
    "# --- 4) Autocorrelació de s -> Rs ---\n",
    "Rs_full = correlate(s, s, mode='full')\n",
    "lags_s = np.arange(-(len(s)-1), len(s))\n",
    "\n",
    "# --- 5) Figura 2x2: x, Rx, s, Rs ---\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "gs = GridSpec(3, 3, figure=fig, width_ratios=[1, 0.2, 1.5], height_ratios=[1, 0.15, 1])\n",
    "\n",
    "ax_x  = fig.add_subplot(gs[0, 0])  # x[n]\n",
    "ax_Rx = fig.add_subplot(gs[0, 2])  # Rx[k]\n",
    "ax_s  = fig.add_subplot(gs[2, 0])  # s[n]\n",
    "ax_Rs = fig.add_subplot(gs[2, 2])  # Rs[k]\n",
    "\n",
    "# (1,1) x[n]\n",
    "ax_x.stem(n_x, x, basefmt=\" \")\n",
    "ax_x.set_title(\"Seqüència x[n] (pols L=3 amb zero-padding)\")\n",
    "ax_x.set_xlabel(\"n\")\n",
    "ax_x.set_ylabel(\"amplitud\")\n",
    "ax_x.grid(True, alpha=0.3)\n",
    "\n",
    "# (1,2) Rx[k]\n",
    "ax_Rx.stem(lags_x, Rx_full, basefmt=\" \")\n",
    "ax_Rx.set_title(\"Autocorrelació Rx[k]\")\n",
    "ax_Rx.set_xlabel(\"k (desplaçament)\")\n",
    "ax_Rx.set_ylabel(\"valor\")\n",
    "ax_Rx.grid(True, alpha=0.3)\n",
    "\n",
    "# (2,1) s[n]\n",
    "ax_s.stem(n_s, s, basefmt=\" \")\n",
    "ax_s.set_title(f\"Seqüència s[n] (3 polsos L={L} separats N={N})\")\n",
    "ax_s.set_xlabel(\"n\")\n",
    "ax_s.set_ylabel(\"amplitud\")\n",
    "ax_s.grid(True, alpha=0.3)\n",
    "\n",
    "# (2,2) Rs[k]\n",
    "ax_Rs.stem(lags_s, Rs_full, basefmt=\" \")\n",
    "ax_Rs.set_title(\"Autocorrelació Rs[k]\")\n",
    "ax_Rs.set_xlabel(\"k (desplaçament)\")\n",
    "ax_Rs.set_ylabel(\"valor\")\n",
    "ax_Rs.grid(True, alpha=0.3)\n",
    "\n",
    "# Fletxa fila 1: de x[n] -> Rx[k]\n",
    "\n",
    "# Fletxes entre eixos (ara hi ha un buit al mig)\n",
    "fig.add_artist(ConnectionPatch(\n",
    "    xyA=(1.08, 0.5), coordsA=ax_x.transAxes,\n",
    "    xyB=(-0.1, 0.5), coordsB=ax_Rx.transAxes,\n",
    "    arrowstyle=\"->\", lw=1.6, mutation_scale=18\n",
    "))\n",
    "fig.add_artist(ConnectionPatch(\n",
    "    xyA=(1.08, 0.5), coordsA=ax_s.transAxes,\n",
    "    xyB=(-0.1, 0.5), coordsB=ax_Rs.transAxes,\n",
    "    arrowstyle=\"->\", lw=1.6, mutation_scale=18\n",
    "))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362d21d6-1ba8-43be-ae57-c71300641baf",
   "metadata": {},
   "source": [
    "**Fixeu-vos en la forma de l'autocorrelació $R_s[k]$ d'un senyal amb repeticions o periodicitats.** <span style=\"color: red;\">A partir d'això responeu la pregunta 3 del qüestionari.</span> Clarament --i lògicament-- l'autocorrelació té el màxim a l'origen, però a quin valor de _k_ (desplaçament) es troben els màxims secundaris? Per què?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8047e7e3-6071-46af-957f-e1dbf56ba741",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">__Qüestió 4__</span> - Sonoritat\n",
    "\n",
    "A efectes d'aquesta pràctica considerarem que un tram de senyal és __sonor__ si compleix les següents condicions:\n",
    "\n",
    "1. Si l'autocorrelació presenta un o més pics locals **diferents del de l'origen**. Tingueu en compte que el màxim d'autocorrelació, $r_{ss}[0]$, s'obté al _centre_ del vector, ja que l'autocorrelació té índexs positius i negatius, simètrics respecte el centre.\n",
    "2. Que el __més gran__ d'aquests pics locals estigui a una distància __N ≥ a 10 mostres__ del centre i que tingui una amplitud relativa al màxim de l'autocorrelació superior a 0,5, és a dir, $r_{ss}[N]/r_{ss}[0] > 0,\\!5$.\n",
    "3. Si l'energia _E_ del senyal del tram és __superior a 0,3__.\n",
    "\n",
    "Modifiqueu el codi de la funció `analitza_segment` per tal d'assignar a la variable `maxims` dos vectors que continguin els índexs i valors dels màxims de l'autocorrelació que compleixen les condicions 1) i 2) anteriors. Suggerim utilitzar la funció `find_peaks` del paquet `SciPy.Signal` per tal de cercar els màxims, passant-li els paràmetres adients. \n",
    "\n",
    "Fet això, assigneu a la variable `sonor`el valor `True`o `False`.\n",
    "\n",
    "Reinicieu l'analitzador per tal de verificar que no teniu errors al codi i comproveu que a la part inferior dreta de la finestra es mostra si el tram que escolliu és sonor o no. Aleshores procediu a respondre la pregunta 4 del qüestionari."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecbb128-6674-44aa-9291-11fdae1c131a",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">__Qüestió 5__</span> - Freqüència de vibració\n",
    "\n",
    "A la qüestió 3 s'ha vist que l'autocorrelació d'un senyal periòdic de període $N$ mostres presentarà __màxims__ a una distància de $\\pm N,\\,\\pm 2N,\\dots$ mostres del centre. Això és així perquè quan desplacem un senyal periódic un nombre de mostres igual a la seva periodicitat, el senyal torna a assemblar-se a sí mateix i per tant l'autocorrelació torna a ser màxima.\n",
    "\n",
    "Aquesta propietat serà útil per a determinar la freqüència de vibració de les cordes vocals, __evidentment només en el cas que estem davant d'un senyal sonor__. A tal efecte:\n",
    "\n",
    "* __Penseu un algorisme__ que calculi la separació $N$ (en mostres) entre el màxim a l'origen i el següent màxim més gran, descartant els màxims locals de menor amplitud que hi pugui haver entre ells.\n",
    "* __Convertiu__ aquesta separació en mostres a separació en segons i, d'aquí a freqüència, consignant aquest darrer valor a la variable « _f_ » de la funció `analitza_segment` de l'Analitzador de veu.\n",
    "\n",
    "Reinicieu l'analitzador per tal de verificar que no teniu errors al codi i comproveu que a la part inferior dreta de la finestra es mostra la freqüència calculada. Aleshores procediu a respondre la pregunta 5 del qüestionari."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5affb3be-2d8d-47aa-bdbe-0c1ef68593f5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e51506d-b4e6-462d-b01e-0f1829d527f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:#BB44DD\">Part C: Síntesi d'un tram de veu</span>\n",
    "\n",
    "En aquest part l'objectiu és provar de __generar veu de forma artificial__.\n",
    "\n",
    "Si volem generar veu sintètica que simuli el millor possible la veu real hem d'aconseguir crear un sistema que generi un senyal amb la __mateixa forma__ que el senyal de veu. Evidentment, com que ja hem vist que el senyal de veu canvia de forma tram a tram, caldrà crear un sistema nou per cada tram. Per tal de fer el problema abordable, __primer farem la síntesi per un sol tram de veu__ i després ho estendrem a la resta de trams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6ed6b0-2f7b-4058-9af4-5ab3404f453e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model matemàtic de la producció de veu\n",
    "\n",
    "Un model matemàtic molt simplificat per a emular el sistema de producció de fonemes consisteix considerar el senyal produït pels pulmons i/o les cordes vocals com una excitació $x[n]$, i els tractes vocal i nasal com un sistema lineal o __filtre__ que emula les seves ressonàncies i modifica aquesta excitació per tal d'obtenir el so desitjat, de tal manera que:\n",
    "\n",
    "1. Modelem el senyal $x[n]$ com un __tren de polsos__ si el so produït és __sonor__, o com a __soroll__ si el so és __sord__.\n",
    "2. Com hem dit abans, els tractes vocal i nasal els modelem amb un filtre que té en compte les ressonàncies d'aquestes cavitats. Matemàticament això es pot aconseguir amb un filtre de tipus __autoregressiu__ d'ordre $P$, cosa que significa que _la sortida en un instant donat és una combinació del valor actual de l'excitació i dels $P$ valors anteriors de la pròpia sortida_. Matemàticament:\n",
    "$$y[n] = b\\cdot x[n] - \\sum_{k=1}^P a_k\\cdot y[n-k]$$\n",
    "L'equació anterior es coneix com una __equació en diferències finites__ (EDF), i és una de les múltiples maneres d'expressar un sistema lineal.\n",
    "\n",
    "Per tant, per poder produir veu de forma artificial haurem de __determinar els coeficients $a_1, \\dots, a_P, b$ del filtre__ i també __escollir adequadament el senyal d'excitació $x[n]$__ segons el fonema que vulguem reproduir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e82e98-94ad-4e0f-8048-bb55e3ea2e04",
   "metadata": {},
   "source": [
    "![image](Síntesi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4520401-510a-41c0-b51f-6af5bcb6da38",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Excitació\n",
    "\n",
    "El tipus d'excitació que hem de posar a l'entrada del filtre dependrà de si el fonema és sonor o sord:\n",
    "\n",
    "* Si el fonema és __sonor__, generarem una excitació consistent en un __tren de deltes__ d'amplitud $\\sqrt{N}$ i separades $N$ mostres, essent $N$ és el període (en mostres) calculat a la qüestió 5.\n",
    "* Si el fonema és __sord__ usarem com a excitació un generador de soroll de variància 1, per exemple gaussià blanc: `np.random.normal(...)`.\n",
    "\n",
    "<span style=\"color:#DD0000;\">En tots els casos la longitud de l'excitació serà de __120 mostres__ (15ms).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d281d-da3b-469b-842f-e30fc9d4bfe3",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">__Qüestió 6__</span>\n",
    "\n",
    "Per què creieu que donem una amplitud de $\\sqrt{N}$ a l'excitació sonora? Responeu-ho al qüestionari."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf73891-6299-4db8-aa86-83283bd6a13d",
   "metadata": {},
   "source": [
    "## Síntesi per filtrat (sistema lineal)\n",
    "\n",
    "L'anàlisi de la veu hauria d'incloure el càlcul dels coeficients $b$ i $a_k$ de l'equació en diferències, però aquesta és una qüestió que ultrapassa els objectius docents del moment. Per aquest motiu, els coeficients del filtre corresponents a cadascun dels trams es proporcionen al fitxer `Coeficients_Frase.npz`, que carregareu tal com es mostra al codi del dessota.\n",
    "\n",
    "Fet això, haureu de completar el codi següent per tal de:\n",
    "\n",
    "1. Escollir un tram de veu de 15 ms de durada.\n",
    "2. Llegir el tram de veu.\n",
    "3. Generar una excitació x[n] adequada en funció de si el tram escollit és sord o sonor.\n",
    "\n",
    "La resta de codi ja està programada (no cal que feu res) i consisteix en generar la veu sintetitzada usant l'excitació que heu generat i comparar visualment el resultat amb la veu original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f945c24-95ee-46e0-8e26-07e2ac7eec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Carreguem els coeficients del filtre en cada tram.\n",
    "# Construïm el nom del fitxer de coeficients\n",
    "base,extensio = FITXER_WAV.split('.', 1)\n",
    "fitxer_coef = \"Coeficients_\" + base + '.npz'\n",
    "# Carreguem amb gestió d'excepcions\n",
    "with np.load(fitxer_coef) as coef:\n",
    "    a = coef['a']       # a[k] contindrà els coeficients a1..aP del tram «k»\n",
    "    b = coef['b']       # b[k] contindrà el coeficient b del tram «k»\n",
    "\n",
    "# ATENCIÓ: Usarem una longitud del tram de síntesi de 120 mostres (15ms) i no 240 (30ms),\n",
    "# perquè en l'anàlisi els trams se solapaven 15ms.\n",
    "Ls = 120\n",
    "\n",
    "# Completeu el codi per tal de sintetitzar i visualitzar el senyal corresponent al tram de veu que us agradi més\n",
    "# Com a suggeriment, podeu provar els trams:\n",
    "#   30, 37, 68, 84, 105, 160, 165 o 242 (sonors) \n",
    "#   47, 250, 261, 290, 325, 335 (sords)\n",
    "num_tram =  \n",
    "tram_original = veu_original[.......]\n",
    "CORRECCIO = 1.59   # Correcció de la pèrdua d'energia a causa de l'enfinestrat de Hamming\n",
    "\n",
    "# Decidireu la sonoritat en funció de l'anàlisi del senyal fet anteriorment a la funció «analitza_segment»\n",
    "sonor =        # Ha de ser «True» o «False»\n",
    "\n",
    "if sonor:\n",
    "    # Genereu l'excitació sonora (tren de deltes d'amplitud sqrt(N)) separades N mostres.\n",
    "    # «f» és la freqüència fonamental del senyal obtinguda en l'analitzador de trams.\n",
    "    f =                      # <<<<< completeu\n",
    "    N =                      # <<<<< completeu\n",
    "    x = CORRECCIO * np.sqrt(N) * .....   # <<<<< completeu\n",
    "else:\n",
    "    # Genereu l'excitació sorda\n",
    "    x = CORRECCIO * np.random.normal( ... )      # <<<<< completeu\n",
    "\n",
    "# Finalment fem passar l'excitació a través del filtre per tal d'obtenir la veu sintetitzada\n",
    "# Això ho farem amb la funció «lfilter», que treballarem més en pràctiques posteriors\n",
    "from scipy.signal import lfilter\n",
    "tram_sintetitzat = lfilter(b[num_tram], a[num_tram], x)\n",
    "\n",
    "# Presenteu en un gràfic el tram de veu original i el sintetitzat, per tal de poder-los comparar\n",
    "fig, (ax1, ax2) = plt.subplots(2,1,sharex=True, sharey=True)\n",
    "t = np.arange(Ls)/fm\n",
    "_ = ax1.plot(t,tram_original, color='C2')\n",
    "_ = ax1.grid(True, which='both', axis='both')\n",
    "_ = ax1.set_title('Comparació entre un tram de veu real i un de sintètic')\n",
    "_ = ax1.set_ylabel('Veu real')\n",
    "\n",
    "_ = ax2.plot(t,tram_sintetitzat)\n",
    "_ = ax2.grid(True, which='both', axis='both')\n",
    "_ = ax2.set_ylabel('Veu sintètica')\n",
    "_ = ax2.set_xlabel('Temps [s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6cbc34-0523-48ef-b943-c6e08444f751",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcb0042-adf5-4197-96ad-e1484bf35b46",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:#BB44DD\">Part D: Síntesi de la frase completa</span>\n",
    "\n",
    "La frase completa la sintetitzarem generant artificialment cadascun dels trams del senyal de veu i concatenant-los tots procurant que les transicions no presentin salts bruscs i siguin el més suaus possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc1a974-15ec-4423-b1e6-3c4972f51529",
   "metadata": {},
   "source": [
    "## Objectius\n",
    "\n",
    "A les parts prèvies (A, B, C) hem vist com analitzar __un tram de veu__ per tal d'extreure'n diferents característiques i paràmetres que el defineixen:\n",
    "\n",
    "- L'energia del tram\n",
    "- Si el senyal del tram correspon a un fonema sord o sonor\n",
    "- En cas de sonoritat, la freqüència fonamental del senyal.\n",
    "\n",
    "També hem vist com podem __sintetitzar__ un senyal semblant a l'analitzat, aplicant una excitació adient a l'entrada d'un sistema lineal que simula les ressonàncies que es produeixen a l'aparell fonador.\n",
    "\n",
    "A continuació el que es pretén és estendre allò que s'ha fet per un sol tram de veu a tots els trams de veu d'una frase, concatenant els diferents senyals sintetitzats __de manera que les transicions entre trams siguin el més suaus possible__, tal com passa en la veu humana."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82e47c1-b5b3-4722-860b-9db0d9097462",
   "metadata": {},
   "source": [
    "## Algorisme\n",
    "\n",
    "Per tal d'aconseguir els objectius fixats haureu d'escriure un petit programa en Python usant la plantilla i fragments de codi que trobareu a continuació. Dividirem la tasca en les parts següents, que són més curtes i simples d'abordar:\n",
    "\n",
    " 0. «Imports» i definició de constants i funcions auxiliars\n",
    " 1. Càrrega del fitxer d'audio\n",
    " 2. Càlcul de quants trams solapats caben en l'àudio carregat\n",
    " 3. Bucle d'anàlisi dels trams i recopilació d'informació\n",
    " 4. Bucle de síntesi de l'àudio (vocoder)\n",
    " 5. Presentació gràfica de resultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac35a59b-2537-4383-8321-0d139a954835",
   "metadata": {},
   "source": [
    "## Part D-0: _Imports_ i definicions.\n",
    "\n",
    "La majoria d'aquest codi ja s'ha posat anteriorment, però el repetim aquí per assegurar-nos que aquesta part \"D\" és autocontinguda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394f348d-c6f7-4858-bc4b-752b69a9cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D-0. Imports i definició de constants\n",
    "\n",
    "from os.path import split, join\n",
    "import numpy as np\n",
    "from scipy.signal import correlate, find_peaks, lfilter, lfilter_zi\n",
    "from scipy.signal.windows import hamming\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio\n",
    "%matplotlib inline\n",
    "#%matplotlib ipympl\n",
    "#%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "# Fem la mida per defecte dels plots una mica més gran\n",
    "plt.rcParams[\"figure.figsize\"] = [14, 10]\n",
    "plt.rcParams[\"figure.dpi\"] = 80\n",
    "\n",
    "FITXER_WAV = \"Frase.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a655bac6-494c-4f73-8f27-4e77d95a25c0",
   "metadata": {},
   "source": [
    "## Part D-1: Definició de variables d'anàlisi/síntesi i funcions auxiliars.\n",
    "\n",
    "En el codi següent, completeu la funció `analitza_tram` per tal que calculi l'energia, sonoritat i freqüència fonamental del senyal (en cas que sigui sonor). El codi és essencialment el mateix que heu hagut de'escriure a l'estudi previ, però __amb una diferència__: <span style=\"color:red\">noteu que aquí no es demana de retornar el valor de la freqüència fonamental del senyal en Hz, sinó la separació __en mostres__ entre els dos màxims més alts de l'autocorrelació</span>. Fem aquesta variació perquè d'aquesta manera serà més senzill unir tots els trams, com veurem més endavant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1497c4a2-d2ce-45d5-948e-9ee806268237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D-1. Definició de variables i funcions auxiliars\n",
    "\n",
    "# Paràmetres de l'anàlisi\n",
    "DURADA_T     = 30E-3        # Longitud dels trams de veu, en segons\n",
    "SOLAPAMENT_T = 15E-3        # Longitud dels solapaments, en segons\n",
    "FREQ_BASE_MAX = 220         # Màxima freq. fonamental dels formants, per evitar falses deteccions\n",
    "SEP_MIN = fm/FREQ_BASE_MAX  # Traduïm l'anterior a separació entre mostres\n",
    "E_MIN_SONOR = 0.1           # Energia mínima per considerar sonor un tram\n",
    "ALÇADA_MIN_PIC = 0.4        # Alçada relativa mínima dels pics de l'autocorrelació per detectar periodicitats\n",
    "CORRECCIO = 1.59            # Factor de correcció per compensar la pèrdua d'amplitud (volum) causada per l'enfinestrat\n",
    "\n",
    "\n",
    "def analitza_tram(tram):\n",
    "    \"\"\"\n",
    "    Funció que analitza un tram i n'extreu diferents característiques.\n",
    "    \n",
    "    Paràmetres: \n",
    "        tram: El fragment de veu a analitzar (np.array) (ja enfinestrat)\n",
    "    \n",
    "    Retorna: \n",
    "        E:     L'energia del senyal contingut al tram (nombre en coma flotant)\n",
    "        sonor: La sonoritat del tram (booleà True/False)\n",
    "        sep:   Si el tram és SONOR, la separació, EN MOSTRES, entre el màxim de l'autocorrelació i el següent pic més gran.\n",
    "               En cas que el tram sigui SORD, sep = np.nan\n",
    "    \"\"\"\n",
    "    ## Tots els paràmetres demanats tenen com a base l'autocorrelació\n",
    "    R = correlate(tram, tram, mode='same', method='direct')\n",
    "\n",
    "    ## Calculeu l'energia, la sonoritat i la separació entre els dos màxims més grans de l'autocorrelació,\n",
    "    ## tenint en compte les constants SEP_MIN, E_MIN_SONOR i ALÇADA_MIN_PIC definides amb anterioritat\n",
    "    E =        # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "    sonor =    # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "    sep =      # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< (Si el tram és SORD feu \"sep = np.nan\" o \"sep = 0\")\n",
    "    \n",
    "    return E, sonor, sep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9202e353-648b-49dc-bce9-05a775aecbea",
   "metadata": {},
   "source": [
    "## Part D-2: Càlcul del nombre de trams.\n",
    "\n",
    "Completeu el codi per tal de calcular:\n",
    "\n",
    "1. Quants trams __solapats__ caben en el fragment de veu.\n",
    "2. L'excés de mostres que no caben en un nombre enter de trams (aquest nombre l'usarem després per tal de completar la veu sintetitzada i fer que tingui la mateixa longitud que l'original).\n",
    "\n",
    "L'única dificultat d'aquesta part és que la presència del solapament pot fer que, si no estem atents, en l'extracció del darrer tram ens quedem sense mostres i es generi una excepció."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff219822-89a5-4973-ad05-2690317cf9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D-2. Càlcul de quants trams solapats caben en l'àudio carregat\n",
    "\n",
    "## Calculeu el valor d'aquestes constants, totes en MOSTRES\n",
    "# LONG_A:      Longitud de les trames d'anàlisi\n",
    "# SOLAPAMENT:  Solapament dels trams d'anàlisi, en mostres\n",
    "# LONG_S:      Longitud de les trames de síntesi\n",
    "# NUM_TRAMS:   Nombre de trames de síntesi que podem arribar a crear\n",
    "LONG_A = \n",
    "SOLAPAMENT =\n",
    "LONG_S = \n",
    "NUM_TRAMS =\n",
    "\n",
    "## Calculeu el nombre «P» de trams que caben al fragment de veu i també l'excés de mostres (si n'hi ha) que no caben en un nombre enter de trams\n",
    "## Noteu que la durada dels trams és de 30ms, però se solapen 15ms, de manera que en el càlcul de N heu de vigilar que en el darrer tram no us quedeu sense mostres\n",
    "P, exces = # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "print(f'El senyal té {P} trams solapats analitzables, amb un excés de {exces} mostres.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3decdeb0-bf46-4ab8-91cf-6b47a024d98a",
   "metadata": {},
   "source": [
    "## Part D-3: Cicle d'anàlisi i síntesi de cada tram.\n",
    "\n",
    "<span style=\"color: red;\">__Aquesta és la part principal de la pràctica__:</span> Es tracta de sintetitzar cada tram de veu usant la informació rellevant sobre el tram __i ajuntar després tots aquests trams pet obtenir la frase sintetitzada sencera__.\n",
    "\n",
    "## Algorisme:\n",
    "\n",
    "1. Carreguem la informació dels coeficients dels filtres sintetitzadors.\n",
    "2. Inicialitzem una llista buida que contindrà la veu sintetitzada de cada tram\n",
    "3. Per cada tram:\n",
    "   - Extraiem les mostres del tram corresponent i en restem el seu valor mig\n",
    "   - Enfinestrem el tram amb una finestra de Hamming (així ens concentrem en la part central i no en els extrems).\n",
    "   - Extraiem la informació útil del tram (energia, sonoritat, separació entre màxims de l'autocorrelació), usant la funció `analitza_tram`.\n",
    "   - Generem una excitació apropiada al tipus de tram: tren de deltes si és sonor i sorroll blanc si és sord.\n",
    "   - Sintetitzem el tram amb el filtre adient i desem el resultat a la llista de trams.\n",
    "4. Un cop calculats tots els trams, els concatenem per obtenir la frase sintetitzada completa. Ajustem la longitud si cal perquè concordi amb la veu original.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1df010-7ece-40cb-8761-8f676522291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D-3. Cicle d'anàlisi i síntesi dels trams\n",
    "\n",
    "# Carreguem la llista de coeficients. Té el mateix nom que el fitxer WAV però amb \"Coeficients_\" davant i extensió «NPZ»\n",
    "# Construïm el nom del fitxer de coeficients\n",
    "fitxer_coef = join(cami, \"Coeficients_\" + nom + '.npz')\n",
    "\n",
    "# Carreguem amb gestió d'excepcions\n",
    "with np.load(fitxer_coef) as coef:\n",
    "    a = coef['a']       # a[k] contindrà els coeficients a1..aP del tram «k»\n",
    "    b = coef['b']       # b[k] contindrà el coeficient b del tram «k»\n",
    "\n",
    "## Calculem la finestra una única vegada\n",
    "FINESTRA = hamming(LONG_A)\n",
    "\n",
    "# Inicialitzem variables\n",
    "veu_sintetitzada = []           # Anirem afegint aquí els trams\n",
    "first_delta_pos = 0                        # S'UTILITZA A LA PART D-5, DE MOMENT NO EN FEU CAS\n",
    "zi = 0*lfilter_zi(b[0], a[0]) #c.i. = 0    # S'UTILITZA A LA PART D-5, DE MOMENT NO EN FEU CAS\n",
    "\n",
    "for num_tram in range(P):\n",
    "    ## Extracció del tram\n",
    "    inici_tram =   # <<<< Calculeu la mostra inicial del tram\n",
    "    tram =         # <<<< Extraieu el fragment de veu. Ha de tenir una durada de 30ms.\n",
    "\n",
    "    ## Abans d'analitzar el tram, restem el (possible) component continu del senyal i l'enfinestrem\n",
    "    tram = tram - np.mean(tram)\n",
    "    tram = tram * FINESTRA\n",
    "\n",
    "    # Calculem paràmetres del tram\n",
    "    E, sonor, sep = analitza_tram(tram)\n",
    "\n",
    "    # Generem l'excitació, sorda/sonora segons l'anàlisi, i amb el període adient\n",
    "    if sonor:\n",
    "        # protecció contra \"sep\" massa petits\n",
    "        if sep < 1:\n",
    "            sep = 1\n",
    "        # Creem l'excitació sonora (tren de deltes)\n",
    "        x =     # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "    else:\n",
    "        # Creem l'excitació sorda (soroll)\n",
    "        x =     # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "    # Filtrem l'excitació amb el filtre indicat pels coeficients\n",
    "    y = lfilter(...)   # <<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "    veu_sintetitzada.append(y)\n",
    "    \n",
    "# Afegiu al final els zeros necessaris per igualar les longituds de les veus original i sintètica i així poder-les representar conjuntament\n",
    "veu_sintetitzada.append(...)  # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "# Concatenem tots els trams de la llista en un únic array NumPy\n",
    "veu_sintetitzada = np.concatenate(veu_sintetitzada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1a5aa0-0d86-4322-8af0-294b690284f9",
   "metadata": {},
   "source": [
    "## Part D-4: Visualització de resultats i desat a fitxer.\n",
    "\n",
    "Presentem un gràfic amb la veu original i sintetitzada, per tal de poder-les comparar. També desem la veu sintètica en un fitxer. Ho fem en blocs de codi diferents per tal que una sortida no tapi la segûent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34329e6-5cba-4f8c-babb-5ca05f9d3e39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# D-4. Presentació i desat de resultats\n",
    "\n",
    "# Plotting\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, sharey=True)\n",
    "t = np.arange(len(veu_original)) / fm\n",
    "_ = ax1.plot(t,veu_original, color='C2')\n",
    "_ = ax1.grid(True, which='both', axis='both')\n",
    "_ = ax1.set_title('Comparació entre veu real i sintètica')\n",
    "_ = ax1.set_ylabel('Veu real')\n",
    "_ = ax2.plot(t,veu_sintetitzada)\n",
    "_ = ax2.grid(True, which='both', axis='both')\n",
    "_ = ax2.set_ylabel('Veu sintètica')\n",
    "_ = ax2.set_xlabel('Temps [s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b8446b-8f6e-4872-b11d-b148c508225a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Escoltem la veu dins del Jupyter\n",
    "veu_sintetitzada = veu_sintetitzada.astype(np.float32)    # <<<< Sembla que és important en sistemes Windows\n",
    "Audio(veu_sintetitzada, rate=fm, autoplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9ca2b2-b5ad-4759-827f-7038a5dab41a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Desat de la veu sintetitzada (OPCIONAL)\n",
    "# Convertim a int16\n",
    "veu_sintetitzada = veu_sintetitzada * 2**15\n",
    "veu_sintetitzada = veu_sintetitzada.astype(np.int16)\n",
    "wavfile.write(join(cami, nom) + '_sintètica.wav', fm, veu_sintetitzada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d4d1b7-b560-45d4-a7a8-14bd4d877f58",
   "metadata": {},
   "source": [
    "## Part D-5: Millora de l'algorisme.\n",
    "\n",
    "Si escolteu el vostre primer intent de síntesi de veu i observeu atentament el senyal generat (fent el _zoom_ que calgui), veureu que la qualitat del resultat és millorable:\n",
    "\n",
    "- S'aprecien discontinuïtats en el senyal de veu\n",
    "- Hi ha intervals de zeros on no hi hauria d'haver senyal.\n",
    "\n",
    "Les causes d'això són diverses i per aquest motiu la tècnica de la síntesi de la veu no és bufar i fer ampolles. Però hi ha dues millores senzilles que podeu fer al vostre algorisme, que faran augmentar molt la qualitat del resultat:\n",
    "\n",
    "1. Cada vegada que genereu un tram de veu fent passar la vostra excitació pel filtre, aquest comença amb unes condicions inicials nul·les i per això la sortida és completament independent de la del tram anterior, cosa que fa que es puguin produir \"salts\" entre trams i/o zones buides de senyal mentre no arriba la primera \"delta\" de l'excitació del tram següent. Per tal d'evitar o minimitzar això, hem de fer entrar en joc les __condicions inicials i finals__ del filtre.\n",
    "\n",
    "    Si consulteu l'ajuda de la funció `lfilter` veureu que accepta com a entrada un paràmetre «`zi`» que són les condicions inicials (també anomenades «estat») a l'inici del càlcul, i retorna un paràmetre «`zf`» que són les condicions (estat) al __final__ del càlcul. <span style=\"color:red\">Així, només cal desar l'estat final de cada tram per tal d'usar-lo com a estat inicial del següent tram</span>. El primer estat de tots serà obviament nul i l'inicialitzarem així:\n",
    "    \n",
    "    ```zi = 0*lfilter_zi(b[0], a[0]) #c.i. = 0```\n",
    "\n",
    "2. Per cada trama sonora generem una excitació consistent en un tren de deltes separades «`sep`» mostres. Però si sempre fem que la primera delta de cada tram estigui a la posició zero, pot passar perfectament que la separació entra l'última delta del tram anterior i la primera del nou tram sigui massa petita/gran, cosa que provocarà una primera resposta massa prop/lluny d'on tocaria i això generarà freqüències que no hi haurien de ser.\n",
    "\n",
    "    En conseqüència, el tren de deltes del nou tram NO ha de començar a la posició zero sinó que ho ha de fer a la posició `sep-Q`, essent _«Q»_ el nombre de mostres entre la darrera delta i el final del tram anterior.\n",
    "    \n",
    "### Per tant, l'objectiu d'aquest apartat és fer les modificacions necessàries al codi de la part 4 per tal de millorar el resultat de la síntesi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46aa50e-624a-4df9-807d-ffb88aacc7d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# D-5a. Introduïu aquí l'algorisme modificat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ab031e-bd7f-467d-8976-bcb4f3263f74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# D-5b. Presentació de resultats\n",
    "\n",
    "# Plotting\n",
    "fig, (ax1, ax2) = plt.subplots(2,1,sharex=True, sharey=True)\n",
    "t = np.arange(len(veu_original)) / fm\n",
    "_ = ax1.plot(t,veu_original, color='C2')\n",
    "_ = ax1.grid(True, which='both', axis='both')\n",
    "_ = ax1.set_title('Comparació entre veu real i sintètica - Algorisme modificat')\n",
    "_ = ax1.set_ylabel('Veu real')\n",
    "_ = ax2.plot(t,veu_sintetitzada)\n",
    "_ = ax2.grid(True, which='both', axis='both')\n",
    "_ = ax2.set_ylabel('Veu sintètica')\n",
    "_ = ax2.set_xlabel('Temps [s]')\n",
    "\n",
    "# Escoltem la veu dins del Jupyter\n",
    "veu_sintetitzada = veu_sintetitzada.astype(np.float32)    # <<<< Sembla que és important en sistemes Windows\n",
    "Audio(veu_sintetitzada, rate=fm, autoplay=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b520f9-9444-46a1-bba9-11abdb68d2cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part D-6: (OPCIONAL) Modificacions al senyal sintètic.\n",
    "\n",
    "Com que tenim accés total als paràmetres de síntesi de la veu, podem jugar a variar-ne alguns per tal d'obtenir un senyal sintètic diferent a l'original. Alguns suggeriments que us fem són:\n",
    "\n",
    "* Podeu «escurçar» o «allargar» la veu modificant la longitud de les trames de síntesi. En aquest cas la veu sintètica tindrà una longitud inferior o superior a la veu original, per la qual cosa haureu d'afegir zeros on correspongui i també recalcular el vector de temps associat, per tal que el codi que genera les gràfiques no es queixi.\n",
    "* Podeu modificar el període fonamental de cada trama (variable `sep`), per exemple incrementant-lo o decrementant-lo un 20% (i passant-lo a enter) o ser molt més creatiu.\n",
    "* Podeu considerar tots els trams sords o sonors (en aquest cas mantenint la variable `sep` del tram anterior).\n",
    "\n",
    "Per cada provatura sintetitzeu el senyal i escolteu el resultat.\n",
    "\n",
    "__NOTA:__ Si voleu fer aquesta part __no modifiqueu el codi que ja funciona__ (i que heu d'entregar), sinó que copieu al dessota el codi de la part 4 i modifiqueu-lo a banda. Si ho desitgeu i considereu que heu trobat algun efecte interessant podeu generar també la gràfica i incloure el reproductor d'Àudio pel nou senyal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fdee45-2ae6-4ac6-8b41-055c2b978fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (OPCIONAL) Copieu el codi de la part 4 i modifiqueu-lo al vostre gust\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e58d2-3d66-4213-99d7-c416fbd5b3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (OPCIONAL) Plotting\n",
    "#fig, (ax1, ax2) = plt.subplots(2,1,sharex=True, sharey=True)\n",
    "#t = np.arange(len(veu_original)) / fm\n",
    "#_ = ax1.plot(t,veu_original, color='C2')\n",
    "#_ = ax1.grid(True, which='both', axis='both')\n",
    "#_ = ax1.set_title('Comparació entre veu real i sintètica')\n",
    "#_ = ax1.set_ylabel('Veu real')\n",
    "#_ = ax2.plot(t,veu_sintetitzada)\n",
    "#_ = ax2.grid(True, which='both', axis='both')\n",
    "#_ = ax2.set_ylabel('Veu sintètica')\n",
    "#_ = ax2.set_xlabel('Temps [s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c31ae1-27af-441c-9d09-ae5b6abc7b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (OPCIONAL) Escoltem la veu dins del Jupyter\n",
    "#veu_sintetitzada = veu_sintetitzada.astype(np.float32)    # <<<< Sembla que és important en sistemes Windows\n",
    "#Audio(veu_sintetitzada, rate=fm, autoplay=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9935bf0-b31c-478a-9bac-3b80a117da02",
   "metadata": {},
   "source": [
    "# <span style=\"color:#BB44DD\">Part E: Entrega de resultats.</span>\n",
    "\n",
    "L'entrega de resultats d'aquesta activitat de laboratori consisteix en aquest mateix «notebook», el qual convertireu prèviament a format HTML seguint els passos següents:\n",
    "\n",
    "1. A la línia 8 del primer bloc de codi, canvieu `%matplotlib qt` per `%matplotlib inline`.\n",
    "2. Reinicieu el _kernel_ i executeu tot el full de dalt a baix amb el símbol de la doble fletxa «⏩», comprovant que no teniu cap error al codi.\n",
    "3. Aneu al menú \"file\" i __exporteu__ el notebook en format __HTML__.\n",
    "4. <span style=\"color: red;\">Obriu el fitxer HTML resultant amb un navegador qualsevol i __comproveu que les gràfiques es veuen, que l'àudio se sent i que el codi és el que voleu entregar__.</span>\n",
    "5. Pugeu el fitxer HTML a la tasca d'ATENEA corresponent. __Entregueu únicament un fitxer per grup de treball__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4236a00e-8cf3-4923-bea3-47a6ecd0fcf6",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<h1 align=\"center\">Final de l'enunciat<h1/>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
